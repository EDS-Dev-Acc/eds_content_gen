# Generated by Django 6.0 on 2025-12-25 05:26

import django.core.validators
import django.db.models.deletion
import django.utils.timezone
import uuid
from django.db import migrations, models


class Migration(migrations.Migration):

    dependencies = [
        ('sources', '0009_crawljob_finalized_at'),
    ]

    operations = [
        migrations.CreateModel(
            name='CrawlJobEvent',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, help_text='Unique identifier (UUID)', primary_key=True, serialize=False, verbose_name='ID')),
                ('created_at', models.DateTimeField(default=django.utils.timezone.now, editable=False, help_text='Timestamp when record was created', verbose_name='Created At')),
                ('updated_at', models.DateTimeField(auto_now=True, help_text='Timestamp when record was last updated', verbose_name='Updated At')),
                ('event_type', models.CharField(choices=[('start', 'Run Started'), ('pause', 'Run Paused'), ('resume', 'Run Resumed'), ('complete', 'Run Completed'), ('fail', 'Run Failed'), ('cancel', 'Run Cancelled'), ('source_start', 'Source Started'), ('source_complete', 'Source Completed'), ('source_fail', 'Source Failed'), ('rate_limit', 'Rate Limited'), ('robots_blocked', 'Blocked by robots.txt'), ('error', 'Error'), ('warning', 'Warning'), ('milestone', 'Milestone')], db_index=True, max_length=30, verbose_name='Event Type')),
                ('severity', models.CharField(choices=[('debug', 'Debug'), ('info', 'Info'), ('warning', 'Warning'), ('error', 'Error'), ('critical', 'Critical')], db_index=True, default='info', max_length=20, verbose_name='Severity')),
                ('message', models.TextField(help_text='Event description', verbose_name='Message')),
                ('url', models.URLField(blank=True, help_text='Related URL if applicable', max_length=2000, verbose_name='URL')),
                ('details', models.JSONField(blank=True, default=dict, help_text='Additional structured data', verbose_name='Details')),
            ],
            options={
                'verbose_name': 'Crawl Job Event',
                'verbose_name_plural': 'Crawl Job Events',
                'db_table': 'crawl_job_events',
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='CrawlJobSeed',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, help_text='Unique identifier (UUID)', primary_key=True, serialize=False, verbose_name='ID')),
                ('created_at', models.DateTimeField(default=django.utils.timezone.now, editable=False, help_text='Timestamp when record was created', verbose_name='Created At')),
                ('updated_at', models.DateTimeField(auto_now=True, help_text='Timestamp when record was last updated', verbose_name='Updated At')),
                ('url', models.URLField(help_text='URL to crawl', max_length=2000, verbose_name='Seed URL')),
                ('label', models.CharField(blank=True, help_text='Optional label for this seed', max_length=100, verbose_name='Label')),
                ('max_pages', models.IntegerField(blank=True, help_text='Override max pages for this seed', null=True, verbose_name='Max Pages')),
                ('crawl_depth', models.IntegerField(blank=True, help_text='Override crawl depth for this seed', null=True, verbose_name='Crawl Depth')),
                ('fetch_mode', models.CharField(blank=True, help_text='Override fetch mode for this seed', max_length=20, verbose_name='Fetch Mode')),
                ('proxy_group', models.CharField(blank=True, help_text='Override proxy group for this seed', max_length=100, verbose_name='Proxy Group')),
                ('status', models.CharField(choices=[('pending', 'Pending'), ('running', 'Running'), ('completed', 'Completed'), ('failed', 'Failed'), ('skipped', 'Skipped')], db_index=True, default='pending', max_length=20, verbose_name='Status')),
                ('started_at', models.DateTimeField(blank=True, null=True, verbose_name='Started At')),
                ('completed_at', models.DateTimeField(blank=True, null=True, verbose_name='Completed At')),
                ('pages_crawled', models.IntegerField(default=0, verbose_name='Pages Crawled')),
                ('articles_found', models.IntegerField(default=0, verbose_name='Articles Found')),
                ('error_message', models.TextField(blank=True, verbose_name='Error Message')),
            ],
            options={
                'verbose_name': 'Crawl Job Seed',
                'verbose_name_plural': 'Crawl Job Seeds',
                'db_table': 'crawl_job_seeds',
                'ordering': ['created_at'],
            },
        ),
        migrations.RemoveIndex(
            model_name='crawljob',
            name='crawl_jobs_finalized_at_idx',
        ),
        migrations.AddField(
            model_name='crawljob',
            name='backfill_from',
            field=models.DateTimeField(blank=True, help_text='Start date for backfill', null=True, verbose_name='Backfill From'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='backfill_to',
            field=models.DateTimeField(blank=True, help_text='End date for backfill', null=True, verbose_name='Backfill To'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='content_types',
            field=models.JSONField(blank=True, default=list, help_text='Types to fetch: html, rss, json, pdf', verbose_name='Content Types'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='cookie_mode',
            field=models.CharField(choices=[('shared', 'Shared Session'), ('none', 'No Cookies'), ('stored', 'Stored Auth Session')], default='shared', help_text='How to handle cookies/sessions', max_length=20, verbose_name='Cookie Handling'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='crawl_depth',
            field=models.IntegerField(default=2, help_text='Maximum link hops from seed', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(20)], verbose_name='Crawl Depth'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='crawl_strategy',
            field=models.CharField(choices=[('depth_first', 'Depth-first'), ('breadth_first', 'Breadth-first'), ('priority', 'Priority-based'), ('focused', 'Focused (Pattern-driven)')], default='breadth_first', help_text='How to prioritize link discovery', max_length=20, verbose_name='Crawl Strategy'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='custom_headers',
            field=models.JSONField(blank=True, default=dict, help_text='Custom HTTP headers as key-value pairs', verbose_name='Custom Headers'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='dedupe_by_fingerprint',
            field=models.BooleanField(default=False, help_text='Skip by content similarity', verbose_name='Dedupe by Fingerprint'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='dedupe_by_url',
            field=models.BooleanField(default=True, help_text='Skip duplicate URLs', verbose_name='Dedupe by URL'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='dedupe_threshold',
            field=models.FloatField(default=0.8, help_text='Similarity threshold for fingerprint deduplication', validators=[django.core.validators.MinValueValidator(0.5), django.core.validators.MaxValueValidator(0.95)], verbose_name='Dedupe Threshold'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='description',
            field=models.TextField(blank=True, help_text='Operator notes about this run', max_length=1000, verbose_name='Description/Notes'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='exclude_patterns',
            field=models.JSONField(blank=True, default=list, help_text='Regex patterns for URLs to exclude', verbose_name='Exclude Patterns'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='fetch_mode',
            field=models.CharField(choices=[('http', 'Standard HTTP (no JS)'), ('headless', 'Headless Browser (JS)'), ('hybrid', 'Hybrid (HTTP first, fallback)')], default='http', help_text='HTTP client or headless browser', max_length=20, verbose_name='Fetch Mode'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='follow_canonical',
            field=models.BooleanField(default=True, help_text='Resolve to canonical URL when provided', verbose_name='Follow Canonical URLs'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='include_patterns',
            field=models.JSONField(blank=True, default=list, help_text='Regex patterns for URLs to include', verbose_name='Include Patterns'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='legal_notes',
            field=models.TextField(blank=True, help_text='Notes about API access or permissions', verbose_name='Legal/Permissions Notes'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='max_concurrent_domain',
            field=models.IntegerField(default=2, help_text='Max concurrent requests per domain', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(100)], verbose_name='Per-Domain Concurrency'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='max_concurrent_global',
            field=models.IntegerField(default=10, help_text='Max concurrent requests globally', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(1000)], verbose_name='Global Concurrency'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='max_pages_domain',
            field=models.IntegerField(default=500, help_text='Maximum pages per domain/source', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(100000)], verbose_name='Max Pages (Domain)'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='max_pages_run',
            field=models.IntegerField(default=1000, help_text='Maximum pages across entire run', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(1000000)], verbose_name='Max Pages (Run)'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='name',
            field=models.CharField(blank=True, help_text='Display name for this run', max_length=100, verbose_name='Run Name'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='normalize_tracking_params',
            field=models.BooleanField(default=True, help_text='Strip UTM, fbclid, etc.', verbose_name='Normalize Tracking Params'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='output_export_format',
            field=models.CharField(blank=True, help_text='json, ndjson, or csv', max_length=20, verbose_name='Export Format'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='output_filename_template',
            field=models.CharField(blank=True, help_text='Template with {run_id}, {date}, {source}', max_length=255, verbose_name='Export Filename Template'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='output_to_db',
            field=models.BooleanField(default=True, help_text='Save results to main database', verbose_name='Store to Database'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='paused_at',
            field=models.DateTimeField(blank=True, help_text='When this run was paused', null=True, verbose_name='Paused At'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='proxy_group',
            field=models.CharField(blank=True, help_text='Specific proxy group if proxy_mode=specific', max_length=100, verbose_name='Proxy Group'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='proxy_mode',
            field=models.CharField(choices=[('none', 'No Proxy'), ('default', 'Default Pool'), ('specific', 'Specific Group')], default='none', help_text='Proxy routing policy', max_length=20, verbose_name='Proxy Usage'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='rate_delay_ms',
            field=models.IntegerField(default=1000, help_text='Base delay between requests per domain', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(60000)], verbose_name='Rate Delay (ms)'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='rate_jitter_pct',
            field=models.IntegerField(default=10, help_text='Random delay variance percentage', validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(100)], verbose_name='Jitter (%)'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='respect_robots',
            field=models.BooleanField(default=True, help_text='Follow robots.txt directives', verbose_name='Respect robots.txt'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='robots_override_notes',
            field=models.TextField(blank=True, help_text='Justification if robots.txt disabled', verbose_name='Robots Override Notes'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='run_extraction',
            field=models.BooleanField(default=True, help_text='Extract and clean article content', verbose_name='Run Article Extraction'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='run_ner',
            field=models.BooleanField(default=False, help_text='Extract named entities', verbose_name='Run NER'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='run_semantic_tagging',
            field=models.BooleanField(default=False, help_text='Apply semantic tags to articles', verbose_name='Run Semantic Tagging'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='run_type',
            field=models.CharField(choices=[('one_off', 'One-off Crawl'), ('scheduled', 'Scheduled Recurring'), ('backfill', 'Backfill/Historical'), ('monitoring', 'Monitoring/Delta-only')], default='one_off', help_text='Type of crawl run', max_length=20, verbose_name='Run Type'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='source_overrides',
            field=models.JSONField(blank=True, default=dict, help_text='Source-specific config overrides keyed by source_id', verbose_name='Per-Source Overrides'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='time_limit_seconds',
            field=models.IntegerField(blank=True, help_text='Max run duration in seconds', null=True, validators=[django.core.validators.MinValueValidator(60)], verbose_name='Time Limit (seconds)'),
        ),
        migrations.AddField(
            model_name='crawljob',
            name='user_agent_profile',
            field=models.CharField(blank=True, help_text='UA profile to use', max_length=100, verbose_name='User-Agent Profile'),
        ),
        migrations.AlterField(
            model_name='crawljob',
            name='status',
            field=models.CharField(choices=[('draft', 'Draft'), ('pending', 'Pending'), ('queued', 'Queued'), ('running', 'Running'), ('paused', 'Paused'), ('completed', 'Completed'), ('failed', 'Failed'), ('cancelled', 'Cancelled')], db_index=True, default='pending', help_text='Current status of the crawl job', max_length=20, verbose_name='Status'),
        ),
        migrations.AddField(
            model_name='crawljobevent',
            name='crawl_job',
            field=models.ForeignKey(help_text='The parent crawl job', on_delete=django.db.models.deletion.CASCADE, related_name='events', to='sources.crawljob', verbose_name='Crawl Job'),
        ),
        migrations.AddField(
            model_name='crawljobevent',
            name='source',
            field=models.ForeignKey(blank=True, help_text='Related source if applicable', null=True, on_delete=django.db.models.deletion.SET_NULL, related_name='crawl_events', to='sources.source', verbose_name='Source'),
        ),
        migrations.AddField(
            model_name='crawljobseed',
            name='crawl_job',
            field=models.ForeignKey(help_text='The parent crawl job', on_delete=django.db.models.deletion.CASCADE, related_name='job_seeds', to='sources.crawljob', verbose_name='Crawl Job'),
        ),
        migrations.AddIndex(
            model_name='crawljobevent',
            index=models.Index(fields=['crawl_job', '-created_at'], name='crawl_job_e_crawl_j_2b6814_idx'),
        ),
        migrations.AddIndex(
            model_name='crawljobevent',
            index=models.Index(fields=['crawl_job', 'event_type'], name='crawl_job_e_crawl_j_ec0bd5_idx'),
        ),
        migrations.AddIndex(
            model_name='crawljobevent',
            index=models.Index(fields=['crawl_job', 'severity'], name='crawl_job_e_crawl_j_753657_idx'),
        ),
        migrations.AddIndex(
            model_name='crawljobevent',
            index=models.Index(fields=['-created_at'], name='crawl_job_e_created_d34a31_idx'),
        ),
        migrations.AddIndex(
            model_name='crawljobseed',
            index=models.Index(fields=['crawl_job', 'status'], name='crawl_job_s_crawl_j_61b140_idx'),
        ),
    ]
